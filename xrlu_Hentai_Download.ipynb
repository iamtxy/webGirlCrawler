{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_Info = [[\"Count\", \"Title\", \"Video Link\"]]\n",
    "\n",
    "for i in range(1,615):\n",
    "    if i%10 == 0:\n",
    "        print(\"----------------the \"+str(i)+\"th video---------------\")\n",
    "    req = Request('https://www.xrlu.com/videos/'+str(i), headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    title = soup.prettify()[(soup.prettify().find(\"<title>\")+7):(soup.prettify().find(\"动漫\")-3)].strip()\n",
    "    title = title.encode(\"gbk\", \"replace\").decode('gbk', 'strict')\n",
    "    video_Link = soup.prettify()[(soup.prettify().find(\"url: '\")+6):(soup.prettify().find(\".mp4\")+4)].strip()\n",
    "    new_Vid = [i,title,video_Link]\n",
    "    video_Info.append(new_Vid)\n",
    "    \n",
    "with open('video_Links.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(video_Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------the 10th video---------------\n",
      "----------------the 20th video---------------\n",
      "----------------the 30th video---------------\n",
      "----------------the 40th video---------------\n",
      "----------------the 50th video---------------\n",
      "----------------the 60th video---------------\n",
      "----------------the 70th video---------------\n",
      "----------------the 80th video---------------\n",
      "----------------the 90th video---------------\n",
      "----------------the 100th video---------------\n",
      "----------------the 110th video---------------\n",
      "----------------the 120th video---------------\n",
      "----------------the 130th video---------------\n",
      "----------------the 140th video---------------\n",
      "----------------the 150th video---------------\n",
      "----------------the 160th video---------------\n",
      "----------------the 170th video---------------\n",
      "----------------the 180th video---------------\n",
      "----------------the 190th video---------------\n",
      "----------------the 200th video---------------\n",
      "----------------the 210th video---------------\n",
      "----------------the 220th video---------------\n",
      "----------------the 230th video---------------\n",
      "----------------the 240th video---------------\n",
      "----------------the 250th video---------------\n",
      "----------------the 260th video---------------\n",
      "----------------the 270th video---------------\n",
      "----------------the 280th video---------------\n",
      "----------------the 290th video---------------\n",
      "----------------the 300th video---------------\n",
      "----------------the 310th video---------------\n",
      "----------------the 320th video---------------\n",
      "----------------the 330th video---------------\n",
      "----------------the 340th video---------------\n",
      "----------------the 350th video---------------\n",
      "----------------the 360th video---------------\n",
      "----------------the 370th video---------------\n",
      "----------------the 380th video---------------\n",
      "----------------the 390th video---------------\n",
      "----------------the 400th video---------------\n",
      "----------------the 410th video---------------\n",
      "----------------the 420th video---------------\n",
      "----------------the 430th video---------------\n",
      "----------------the 440th video---------------\n",
      "----------------the 450th video---------------\n",
      "----------------the 460th video---------------\n",
      "----------------the 470th video---------------\n",
      "----------------the 480th video---------------\n",
      "----------------the 490th video---------------\n",
      "----------------the 500th video---------------\n",
      "----------------the 510th video---------------\n",
      "----------------the 520th video---------------\n",
      "----------------the 530th video---------------\n",
      "----------------the 540th video---------------\n",
      "----------------the 550th video---------------\n",
      "----------------the 560th video---------------\n",
      "----------------the 570th video---------------\n",
      "----------------the 580th video---------------\n",
      "----------------the 590th video---------------\n",
      "----------------the 600th video---------------\n",
      "----------------the 610th video---------------\n"
     ]
    }
   ],
   "source": [
    "#create 2d list to store video informations\n",
    "video_Info = [[\"Count\", \"Title\", \"Video Link\"]]\n",
    "\n",
    "#for loop to got through all videos\n",
    "for i in range(1,615):\n",
    "    if i%10 == 0:\n",
    "        print(\"----------------the \"+str(i)+\"th video---------------\")\n",
    "    #request webpage html\n",
    "    req = Request('https://www.xrlu.com/videos/'+str(i), headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    #create a soup\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    # search for title within the html file\n",
    "    title = soup.prettify()[(soup.prettify().find(\"<title>\")+7):(soup.prettify().find(\"动漫\")-3)].strip()\n",
    "    title = title.encode(\"gbk\", \"replace\").decode('gbk', 'strict') #take out invalid characters\n",
    "    # search for video link within html file\n",
    "    video_Link = soup.prettify()[(soup.prettify().find(\"url: '\")+6):(soup.prettify().find(\".mp4\")+4)].strip()\n",
    "    #save count, title, video link into a list \n",
    "    new_Vid = [i,title,video_Link]\n",
    "    #save list into the 2d list\n",
    "    video_Info.append(new_Vid)\n",
    "    \n",
    "#write 2d list into csv\n",
    "with open('video_Links.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(video_Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
